[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "title",
    "section": "",
    "text": "Under construction (16.11.2022) Here you find this and that.\n\nThese are (probably) all the libraries you will need\n\nlibrary(adehabitatHS)\nlibrary(data.table)\nlibrary(cowplot)\nlibrary(drc)\nlibrary(lubridate)\nlibrary(MASS)\nlibrary(pdftools)\nlibrary(png)\nlibrary(raster)\nlibrary(rgdal)\nlibrary(rgeos)\nlibrary(rminer)\nlibrary(sf)\nlibrary(snow)\nlibrary(splitstackshape)\nlibrary(terra)\nlibrary(tidyverse)\nlibrary(tmap)"
  },
  {
    "objectID": "disturbance_prediction.html",
    "href": "disturbance_prediction.html",
    "title": "\n1  Disturbance prediction\n",
    "section": "",
    "text": "using the disturbance assessments from the field"
  },
  {
    "objectID": "disturbance_prediction.html#load-files-and-clean",
    "href": "disturbance_prediction.html#load-files-and-clean",
    "title": "\n1  Disturbance prediction\n",
    "section": "\n1.1 Load files and clean",
    "text": "1.1 Load files and clean\n\n# Load the disturbance field data\nplots<- read.csv(\"datafiles/goose_grubbing_small_veg_goose.csv\", sep=\";\")\n\n# Load the spatial file for field plots\nplot_sf<-read_sf(\"datafiles/grubbing_small_plot.shp\")\n\n# Calculate the centroid of the plots\nplot_sf$centroid <- st_centroid(plot_sf$geometry)\n\n# Extract central coordinates of small plots\nplot_sf <- plot_sf  %>% \n  mutate(x = map_dbl(geometry, ~st_centroid(.x)[[1]]),\n         y = map_dbl(geometry, ~st_centroid(.x)[[2]]))\n\n# Create dataframe with xy coordinates as columns\ncoordinates <- plot_sf %>% st_drop_geometry() %>% dplyr::select(sub_plot=Name,x,y)\n\n# Clean the dataset, group classes and add presence absence columns\ndf <-dplyr::select(plots, sub_plot, group_of_plots, date_snow_free, veg =field_class_vier, bull_pa, pick_pa, date_disturbance) %>% \n  filter(!(veg == 'na')) %>%\n  filter(!(date_snow_free == 'late')) %>%\n  mutate(disturbance = ifelse((bull_pa < 1) & (pick_pa < 1), 0, 1)) %>%\n  inner_join(coordinates) %>% \n  mutate(veg_class = recode(veg, 'wet' = 'moist'))\ndf$veg_class<-gsub('hmo', 'dry',df$veg_class)\n\ndf$pick_pa<-df$disturbance-df$bull_pa\n\n# Add new column that translates snowfree date into snow-free days\ndf$snow<-df$date_snow_free\n\ndf$snow[df$snow == \"153\"]<-2\ndf$snow[df$snow == \"150\"]<-6\ndf$snow[df$snow == \"146\"]<-10\ndf$snow[df$snow == \"142\"]<-14\ndf$snow[df$snow == \"138\"]<-18\ndf$snow[df$snow == \"134\"]<-22\n\n# Change to factor and numeric where necessary\ndf$veg_class<- as.factor(df$veg_class)\ndf$snow<- as.numeric(df$snow)\n\nwrite_csv(df, file = \"data_output/disturbance_dataset_clean.csv\")"
  },
  {
    "objectID": "disturbance_prediction.html#modelling-disturbance-probability",
    "href": "disturbance_prediction.html#modelling-disturbance-probability",
    "title": "\n1  Disturbance prediction\n",
    "section": "\n1.2 Modelling disturbance probability",
    "text": "1.2 Modelling disturbance probability\n\n# Select data for disturbance model (snow-free date)\nd <- dplyr::select(df, veg_class, snow=date_snow_free, disturbance)\nd$snow<-as.numeric(d$snow)\nd$expsnow <- exp(d$snow)\nlevels(d$veg_class) <- c(\"dwarf shrub heath\", \"moss tundra\")\n\n\n# Disturbance model with different slope for both vegetation classes\nmossheath.drm32 <- drm(disturbance ~ expsnow, veg_class, data = d,\n                       fct = LL2.3(), type = \"binomial\", pmodels = data.frame(veg_class, veg_class, veg_class))\nmossheath.drm32\nsummary(mossheath.drm32)\n\n# Predict the model to 100 points for plotting\npred.newdata<-cbind.data.frame(snow=seq(134,153,length=100),expsnow=exp(seq(134,153,length=100)),\n                               veg_class=rep(c(\"dwarf shrub heath\", \"moss tundra\"),each=100))\n\npred.newdata$pred.dm<-predict(mossheath.drm32,newdata=pred.newdata)\n\nplot(pred.dm~snow, data=pred.newdata,subset=veg_class==\"dwarf shrub heath\",\n     type=\"l\",col=\"red\", ylim=c(0,1),ylab=\"Prop grubbing\")\nlines(pred.dm~snow, data=pred.newdata,subset=veg_class==\"moss tundra\",col=\"blue\")\n# Disturbance model with same slope for both vegetation classes\npred.newdata<-cbind.data.frame(snow=seq(134,153,length=100),expsnow=exp(seq(134,153,length=100)),\n                               veg_class=rep(c(\"dwarf shrub heath\", \"moss tundra\"),each=100))\nmossheath.drm32.b <- drm(disturbance ~ expsnow, veg_class, data = d,\n                         fct = LL2.3(), type = \"binomial\", pmodels = data.frame(1, veg_class, veg_class))\nsummary(mossheath.drm32.b)\npred.newdata$pred.dm.b<-predict(mossheath.drm32.b,newdata=pred.newdata)"
  },
  {
    "objectID": "disturbance_prediction.html#calculate-means-and-plot-the-predictions",
    "href": "disturbance_prediction.html#calculate-means-and-plot-the-predictions",
    "title": "\n1  Disturbance prediction\n",
    "section": "\n1.3 Calculate means and plot the predictions",
    "text": "1.3 Calculate means and plot the predictions\n\n# Calculate the mean disturbance per vegetation class and snowfree date\nmean_veg_snow<-group_by(d, snow, veg_class) %>%\n  summarize_at(vars(disturbance),\n               list(~length(.),\n                    ~mean(., na.rm = T)))\n# Move one point minimally so that they are both visible and don't overlap\nmean_veg_snow[7,1] = 146.2\n\n\n# Plot the disturbance model\npdf(\"Figures/grubbing_model_drc.pdf\",         # File name\n    width = 5, height = 5, # Width and height in inches\n    bg = \"white\")\n\nplot(range(mean_veg_snow[,1]), range(c(0,1)), type='n', ylab=\"Disturbance probability (0-1)\", xlab=\"Snowmelt date (Julian date)\")\nlines(pred.dm.b~snow, lwd = 2, data=pred.newdata,subset=veg_class==\"moss tundra\",col=\"#B21EB6\")\nlines(pred.dm.b~snow, lwd = 2, data=pred.newdata,subset=veg_class==\"dwarf shrub heath\",col=\"#FFC000\")\npar(new=TRUE)\nplot(mean_veg_snow$snow, mean_veg_snow$mean, axes=FALSE, ylab=\"\", xlab=\"\", col=\"black\", bg=c('#FFC000', '#B21EB6')[as.numeric(mean_veg_snow$veg_class)], pch=21)\nlegend(134, 0.15, legend=c(\"moss tundra\", \"dwarf-shrub heath\"), col=c(\"#B21EB6\", \"#FFC000\"), \n       lty=1, lwd = 2, cex=0.8, box.lty=0)\n\ndev.off()"
  },
  {
    "objectID": "disturbance_prediction.html#run-model-for-use-in-next-scripts",
    "href": "disturbance_prediction.html#run-model-for-use-in-next-scripts",
    "title": "\n1  Disturbance prediction\n",
    "section": "\n1.4 Run model for use in next scripts",
    "text": "1.4 Run model for use in next scripts\nRunning the same model with vegetation classes as with factor names 1 or 2 instead of class names to use in the disturbance maps (disturbance_map_satellite, disturbance_map_drone). You can avoid this step by running the model with numeric factors from the beginning and then relabel for plotting instead…\n\nd_map <- dplyr::select(df, veg_class, snow=date_snow_free, disturbance)\nd_map$snow<-as.numeric(d_map$snow)\nd_map$expsnow <- exp(d_map$snow)\nlevels(d_map$veg_class) <- c(2,1)\n\nmap.drm32 <- drm(disturbance ~ expsnow, veg_class, data = d_map,\n                         fct = LL2.3(), type = \"binomial\", pmodels = data.frame(1, veg_class, veg_class))"
  },
  {
    "objectID": "disturbance_prediction.html#libraries",
    "href": "disturbance_prediction.html#libraries",
    "title": "1  Disturbance prediction",
    "section": "1.1 Libraries",
    "text": "1.1 Libraries\nThese are (probably) all the libraries you will need\n\nlibrary(drc)\nlibrary(png)\nlibrary(sf)\nlibrary(tidyverse)"
  },
  {
    "objectID": "satellite_snowcover_map.html",
    "href": "satellite_snowcover_map.html",
    "title": "\n2  Satellite snow cover map\n",
    "section": "",
    "text": "This script loads the classified satellite raster images and merges them into one stack where each stacked layer indicates which areas became free from snow since the last date"
  },
  {
    "objectID": "satellite_snowcover_map.html#produce-a-single-rasterstack-for-new-snow-free-areas-in-each-stack",
    "href": "satellite_snowcover_map.html#produce-a-single-rasterstack-for-new-snow-free-areas-in-each-stack",
    "title": "\n2  Satellite snow cover map\n",
    "section": "\n2.1 Produce a single rasterstack for new snow-free areas in each stack",
    "text": "2.1 Produce a single rasterstack for new snow-free areas in each stack\nThis is script cleans the classified snow/no snow satellite rasters and stacks them into a single file I made a “manual loop” where I repeated the same chunk of code for each layer. Please don’t judge. :)\n\n# Load the classified snow - no snow satellite images, only select the layer that has the snow data (layer 6)\n\nsn0510 = rast(\"raster_input/d_20190510_fin.tif\")\nsn0510<-sn0510[[6]]\n\nsn0522 = rast(\"raster_input/d_20190522_fin.tif\")\nsn0522<-sn0522[[6]]\n\nsn0523 = rast(\"raster_input/d_20190523_fin.tif\")\nsn0523<-sn0523[[6]]\n\nsn0527 = rast(\"raster_input/d_20190527_fin.tif\")\nsn0527<-sn0527[[6]]\n\nsn0528 = rast(\"raster_input/d_20190528_fin.tif\")\nsn0528<-sn0528[[6]]\n\nsn0601 = rast(\"raster_input/d_20190601_fin.tif\")\nsn0601<-sn0601[[6]]\n\n# This is a procedure to label each raster layer with the area that is newly snow-free\n\n# Reclassify the first layer (1 snow, 5 snow-free)\nsn0510_re <- classify(sn0510, cbind(NA, 1))\nsn0510_re <- classify(sn0510_re, cbind(0, 5))\n\n\n# Rename the first layer \nsn1<-sn0510_re\n\n#reclassify new layer\nsn_re <- classify(sn0522, cbind(NA, 1))\n\n# start repeated chunk\n\n# reclassify the snow/snow free layers to make different from the one above\n# 10 for snow, 20 for snowfree\nsn_re <- classify(sn_re, cbind(0, 10))\nsn_re <- classify(sn_re, cbind(1, 20))\n\n# add the previous layer to the new one\nsn<-sn_re+sn1\n\n# reclassify the added layer, all areas that had had snow but are newly free of snow get the label 5, all other 1\nm <- c(11, 1,\n       15, 5,\n       21, 1,\n       25, 1)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn1 <- classify(sn, rclmat, include.lowest=TRUE)\n\n# --- end of chunk\n\n\n#rename the new layer to keep it\nsn0522_x<-sn1\n\n#reclassify the next new layer, and then repeat the chunk\nsn_re <- classify(sn0523, cbind(NA, 1))\n\n# start repeated chunk\n\n# reclassify the snow/snow free layers to make different from the one above\n# 10 for snow, 20 for snowfree\nsn_re <- classify(sn_re, cbind(0, 10))\nsn_re <- classify(sn_re, cbind(1, 20))\n\n# add the previous layer to the new one\nsn<-sn_re+sn1\n\n# reclassify the added layer, all areas that had had snow but are newly free of snow get the label 5, all other 1\nm <- c(11, 1,\n       15, 5,\n       21, 1,\n       25, 1)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn1 <- classify(sn, rclmat, include.lowest=TRUE)\n\n# --- end of chunk\n\n#rename\nsn0523_x<-sn1\n\n#reclassify new layer\nsn_re <- classify(sn0527, cbind(NA, 1))\n\n# start repeated chunk\n\n# reclassify the snow/snow free layers to make different from the one above\n# 10 for snow, 20 for snowfree\nsn_re <- classify(sn_re, cbind(0, 10))\nsn_re <- classify(sn_re, cbind(1, 20))\n\n# add the previous layer to the new one\nsn<-sn_re+sn1\n\n# reclassify the added layer, all areas that had had snow but are newly free of snow get the label 5, all other 1\nm <- c(11, 1,\n       15, 5,\n       21, 1,\n       25, 1)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn1 <- classify(sn, rclmat, include.lowest=TRUE)\n\n# --- end of chunk\n\n#rename\nsn0527_x<-sn1\n\n#reclassify new layer\nsn_re <- classify(sn0528, cbind(NA, 1))\n\n# start repeated chunk\n\n# reclassify the snow/snow free layers to make different from the one above\n# 10 for snow, 20 for snowfree\nsn_re <- classify(sn_re, cbind(0, 10))\nsn_re <- classify(sn_re, cbind(1, 20))\n\n# add the previous layer to the new one\nsn<-sn_re+sn1\n\n# reclassify the added layer, all areas that had had snow but are newly free of snow get the label 5, all other 1\nm <- c(11, 1,\n       15, 5,\n       21, 1,\n       25, 1)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn1 <- classify(sn, rclmat, include.lowest=TRUE)\n\n# --- end of chunk\n\n#rename\nsn0528_x<-sn1\n\n#reclassify new layer\nsn_re <- classify(sn0601, cbind(NA, 1))\n\n# start repeated chunk\n\n# reclassify the snow/snow free layers to make different from the one above\n# 10 for snow, 20 for snowfree\nsn_re <- classify(sn_re, cbind(0, 10))\nsn_re <- classify(sn_re, cbind(1, 20))\n\n# add the previous layer to the new one\nsn<-sn_re+sn1\n\n# reclassify the added layer, all areas that had had snow but are newly free of snow get the label 5, all other 1\nm <- c(11, 1,\n       15, 5,\n       21, 1,\n       25, 1)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn1 <- classify(sn, rclmat, include.lowest=TRUE)\n\n# --- end of chunk\n\n#rename\nsn0601_x<-sn1\n\n# add all the reclassified layers together into 1 raster stack\nsn6<-c(sn0510_re, sn0522_x, sn0523_x, sn0527_x, sn0528_x, sn0601_x)\n\n# load the extent of the study area\nsat_extent= read_sf(\"datafiles/goose_survey_1000.shp\")\n\n# crop the snow raster to the study extent\nsn6_crop=crop(sn6, vect(sat_extent))\nsn6_crop=mask(sn6_crop, vect(sat_extent))\n\nnames(sn6_crop)<-c('snow130', 'snow142', 'snow143', 'snow147', 'snow148', 'snow152')"
  },
  {
    "objectID": "satellite_snowcover_map.html#make-snow-cover-maps-for-dates-where-there-was-a-big-gap-in-data",
    "href": "satellite_snowcover_map.html#make-snow-cover-maps-for-dates-where-there-was-a-big-gap-in-data",
    "title": "2  Satellite snowcover map",
    "section": "2.2 Make snow-cover maps for dates where there was a big gap in data",
    "text": "2.2 Make snow-cover maps for dates where there was a big gap in data\n\n# Calculate the snow extent for the 30th of May\n\n#load rasters and reclassify (early date the vegetation is labelled 1, the late date, snow gets labelled 1)\nsn28 <- classify(sn6_crop$snow148, cbind(5, NA))\nsn01 <- classify(sn6_crop$snow152, cbind(1, NA))\nsn01 <- classify(sn01, cbind(5, 1))\n\n#calculate distance to vegetation edge for the early data and snow edge for the late date\nsn28_dist <- distance(sn28)\nsn01_dist <- distance(sn01)\n\n# Rename\nsn01x<-sn01_dist\nsn28x<-sn28_dist\n\n#Find the areas that are in the middle of the vegetation buffer of the early date and the snow buffer of the late day\n# this is to estimate the snow cover for the date between\n\nsn01x[sn01x <  sn28x] <- 500\n\nm <- c(0, 498, 0,\n       498, 501, 1)\nrclmat <- matrix(m, ncol=3, byrow=TRUE)\nsn01x <- classify(sn01x, rclmat, include.lowest=TRUE)\n\n# reclassify the late date layer \nsn01y <- classify(sn6_crop$snow152, cbind(5, 0))\n\n# multiply with the late date layer and reclassify to add the interpolated snow cover to the snow cover that is still there during the later date\nsn01xy<-sn01y*sn01x\n\nsn30<-sn6_crop$snow152+sn01xy\n\nm <- c(1, 1,\n       2, 5,\n       5, 5)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn30x <- classify(sn30, rclmat, include.lowest=TRUE)\n\n\n# Do the same kind of interpolation for the 18th of May\n\n# Reclassify the first layer (1 snow, 5 snow-free)\nsn10 <- classify(sn6_crop$snow130, cbind(5, NA))\nsn22 <- classify(sn6_crop$snow142, cbind(1, NA))\nsn22 <- classify(sn22, cbind(5, 1))\n\n#calculate distance to veg and snow edge\nsn10_dist <- distance(sn10)\nsn22_dist <- distance(sn22)\n\nsn10x<-sn10_dist\nsn22x<-sn22_dist\n\nsn22x[sn22x <  sn10x] <- 5500\n\nm <- c(0, 5020, 0,\n       5020, 5600, 1)\nrclmat <- matrix(m, ncol=3, byrow=TRUE)\nsn22x <- classify(sn22x, rclmat, include.lowest=TRUE)\n\nsn22y <- classify(sn6_crop$snow142, cbind(5, 0))\n\nsn22xy<-sn22y*sn22x\n\nsn18<-sn6_crop$snow142+sn22xy\n\nm <- c(1, 1,\n       2, 5,\n       5, 5)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn18x <- classify(sn18, rclmat, include.lowest=TRUE)"
  },
  {
    "objectID": "satellite_snowcover_map.html#stack-the-eight-rasters-into-single-stack-and-save-outputs",
    "href": "satellite_snowcover_map.html#stack-the-eight-rasters-into-single-stack-and-save-outputs",
    "title": "\n2  Satellite snow cover map\n",
    "section": "\n2.3 Stack the eight rasters into single stack and save outputs",
    "text": "2.3 Stack the eight rasters into single stack and save outputs\n\n# Stack the new rasters together with the other ones\nsn8<-c(sn6_crop$snow130, sn18x, sn6_crop$snow142, sn6_crop$snow143, sn6_crop$snow147, sn6_crop$snow148, sn30x, sn6_crop$snow152)\n\n# Rename the layers in the stack\nnames(sn8)<-c('snow130','snow138', 'snow142', 'snow143', 'snow147', 'snow148', 'snow150', 'snow152')\n\n# Save the raster or use further in \"sat_grubbing_map\"\nwriteRaster(sn8, \"raster_output/raster_snow_all8_layers_cleaned_clipped.tif\", overwrite=TRUE)\n\n# Make a frequenct table of snowmelt\nfreqy<-as.data.frame(freq(sn8)) \nfreqy$julian<-c(130,130, 138,138, 142,142,143,143,147,147,148,148,150,150,152,152)\nfreqy$value<-as.factor(freqy$value)\nlevels(freqy$value) <- c(\"snow-free\",\"snow\")\nwrite.table(freqy, file = \"data_output/satellite_snow_no_snow.txt\", append = FALSE, sep =  \"\\t\", dec = \".\",\n            row.names = FALSE, col.names = TRUE)\n\nplot(sn8)"
  },
  {
    "objectID": "satellite_snowcover_map.html#make-snow-cover-maps-for-dates-where-there-was-a-timegaps-in-the-data",
    "href": "satellite_snowcover_map.html#make-snow-cover-maps-for-dates-where-there-was-a-timegaps-in-the-data",
    "title": "\n2  Satellite snow cover map\n",
    "section": "\n2.2 Make snow cover maps for dates where there was a timegaps in the data",
    "text": "2.2 Make snow cover maps for dates where there was a timegaps in the data\n\n# Calculate the snow extent for the 30th of May\n\n#load rasters and reclassify (early date the vegetation is labelled 1, the late date, snow gets labelled 1)\nsn28 <- classify(sn6_crop$snow148, cbind(5, NA))\nsn01 <- classify(sn6_crop$snow152, cbind(1, NA))\nsn01 <- classify(sn01, cbind(5, 1))\n\n#calculate distance to vegetation edge for the early data and snow edge for the late date\nsn28_dist <- distance(sn28)\nsn01_dist <- distance(sn01)\n\n# Rename\nsn01x<-sn01_dist\nsn28x<-sn28_dist\n\n#Find the areas that are in the middle of the vegetation buffer of the early date and the snow buffer of the late day\n# this is to estimate the snow cover for the date between\n\nsn01x[sn01x <  sn28x] <- 500\n\nm <- c(0, 498, 0,\n       498, 501, 1)\nrclmat <- matrix(m, ncol=3, byrow=TRUE)\nsn01x <- classify(sn01x, rclmat, include.lowest=TRUE)\n\n# reclassify the late date layer \nsn01y <- classify(sn6_crop$snow152, cbind(5, 0))\n\n# multiply with the late date layer and reclassify to add the interpolated snow cover to the snow cover that is still there during the later date\nsn01xy<-sn01y*sn01x\n\nsn30<-sn6_crop$snow152+sn01xy\n\nm <- c(1, 1,\n       2, 5,\n       5, 5)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn30x <- classify(sn30, rclmat, include.lowest=TRUE)\n\n\n# Do the same kind of interpolation for the 18th of May\n\n# Reclassify the first layer (1 snow, 5 snow-free)\nsn10 <- classify(sn6_crop$snow130, cbind(5, NA))\nsn22 <- classify(sn6_crop$snow142, cbind(1, NA))\nsn22 <- classify(sn22, cbind(5, 1))\n\n#calculate distance to veg and snow edge\nsn10_dist <- distance(sn10)\nsn22_dist <- distance(sn22)\n\nsn10x<-sn10_dist\nsn22x<-sn22_dist\n\nsn22x[sn22x <  sn10x] <- 5500\n\nm <- c(0, 5020, 0,\n       5020, 5600, 1)\nrclmat <- matrix(m, ncol=3, byrow=TRUE)\nsn22x <- classify(sn22x, rclmat, include.lowest=TRUE)\n\nsn22y <- classify(sn6_crop$snow142, cbind(5, 0))\n\nsn22xy<-sn22y*sn22x\n\nsn18<-sn6_crop$snow142+sn22xy\n\nm <- c(1, 1,\n       2, 5,\n       5, 5)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn18x <- classify(sn18, rclmat, include.lowest=TRUE)"
  },
  {
    "objectID": "satellite_vegetation_map.html#extract-the-pixel-values-at-training-point-locations",
    "href": "satellite_vegetation_map.html#extract-the-pixel-values-at-training-point-locations",
    "title": "\n3  Valley scale (vegetation map)\n",
    "section": "\n3.1 Extract the pixel values at training point locations",
    "text": "3.1 Extract the pixel values at training point locations\n\n# Load the satellite summer image \nsati<-rast(\"raster_input/s2_adventdalen_20190727_new.tif\")\n\n# Load the training data fo the vegetation classes\ntraining= read_sf(\"datafiles/training_sat.shp\")\n\n# Load an extent file for the study area\nsat_extent= read_sf(\"datafiles/goose_survey_1000.shp\")\n\n# Extract pixel values at training points \nsat_extract<-terra::extract(sati, vect(training))\nsat<-cbind(sat_extract, training)\nsat$Id<-as.factor(sat$Id)\n\n\n# Visualize the pixel values for the classes if you want \nsat_long<-pivot_longer(sat,\n                       cols = B2:B8 ,\n                       names_to = 'layer',\n                       values_to = 'score')\n\nggplot() +\n  geom_boxplot(data= sat_long, aes(x = layer, y=score, fill=Id))"
  },
  {
    "objectID": "satellite_vegetation_map.html#run-the-random-forest-with-subsets-of-the-data-to-check-how-robust-the-classification-is",
    "href": "satellite_vegetation_map.html#run-the-random-forest-with-subsets-of-the-data-to-check-how-robust-the-classification-is",
    "title": "\n3  Valley scale (vegetation map)\n",
    "section": "\n3.2 Run the random forest with subsets of the data to check how robust the classification is",
    "text": "3.2 Run the random forest with subsets of the data to check how robust the classification is\n\n#make a simple dataset to reduce to one entry per ground truth point (ID column and class column)\nsat_data<-sat\nsat_sub_data<-sat_data[,c(1,6)]\nsat_sub_data$Id<-as.factor(sat_sub_data$Id)\nsat_sub_data<-unique(sat_sub_data)\n\nsat_output<-list() \nsat_all.scores<-c()\nsat_c_matrix = matrix(0, 3, 3)\nsat_all_cm<-c()\nfor(run.int in 1:30 ){\n  run<-as.character(run.int)\n  out_sat <- stratified(sat_sub_data, c(\"Id\"), 0.7)\n  \n  #create training dataset from the \"out dataframe\"\n  sat_training.data<-sat_data[sat_data$ID %in% out_sat$ID,]\n  \n  #create validation dataset from the remaining data\n  sat_validation.data<-sat_data[!sat_data$ID %in% out_sat$ID,]\n  sat_validation.data<-sat_validation.data[,c(2:6)]\n  \n  #remove rows not to be included\n  sat_training.data<-sat_training.data[,c(2:6)]\n  sat_training.data$Id<-as.factor(sat_training.data$Id)\n  \n  #Run random forest model\n  M_sat=rminer::fit(Id~.,sat_training.data,model=\"randomForest\", task = \"class\")\n  sat_output[[run]]<-list(model=M_sat)\n  #create dataframe whilst extracting the descriptor \n  sat_table_res <- as.data.frame(M_sat@object$importance)\n  \n  #change order of values in column from highest to lowest\n  sat_table_res_S <- sat_table_res[order(sat_table_res$MeanDecreaseAccuracy),] \n  \n  #plot the decriptor importance as barplot\n  par(mar=c(4,5,4,4))\n  barplot(sat_table_res_S$MeanDecreaseAccuracy,\n          horiz=\"TRUE\", col=\"darkgreen\", xlab=\"importance\", xlim=c(0,0.9),\n          names.arg=row.names(sat_table_res_S), cex.names=0.5, las=1, border=F)\n  \n  sat_output[[run]][[\"importance\"]]<-sat_table_res_S\n  \n  # use the model to predict the classes in the validation dataset\n  sat_validation.data$pred.Id=rminer::predict(M_sat,sat_validation.data)\n  \n  sat_validation.data$Id<-as.factor(sat_validation.data$Id)\n  \n  # compare predicted versus observed data\n  sat_c.m<-rminer::mmetric(sat_validation.data$Id, sat_validation.data$pred.Id, metric=c(\"ALL\"))\n  sat_c.m1<-rminer::mmetric(sat_validation.data$Id, sat_validation.data$pred.Id, metric=c(\"CONF\"))\n  \n  # add all metrics to outputs and make table\n  sat_output[[run]][[\"accuracy\"]]<-sat_c.m\n  sat_all.scores<-rbind(sat_all.scores, sat_c.m)\n  \n  # make a extra output for confusion matrix and total summed confusion matrix\n  sat_output[[run]][[\"cfm\"]]<-sat_c.m1$conf\n  sat_c_matrix<-sat_c_matrix + sat_c.m1$conf\n  \n  # make a long table with all confusion matrices\n  sat_all_cm<-rbind(sat_all_cm, sat_c.m1$conf)\n}\ndev.off()\n\n### Classification scores\n\nsat_all.scores.df<-data.frame(sat_all.scores)"
  },
  {
    "objectID": "satellite_vegetation_map.html#create-vegetation-map",
    "href": "satellite_vegetation_map.html#create-vegetation-map",
    "title": "\n3  Valley scale (vegetation map)\n",
    "section": "\n3.3 Create vegetation map",
    "text": "3.3 Create vegetation map\n\n## Run the random forest classifier\nM_sat=rminer::fit(Id~.,sat[,2:6],model=\"randomForest\", task = \"class\")\n\n# create dataframe whilst extracting the descriptor \ntable_res <- as.data.frame(M_sat@object$importance)\n\n# change order of values in column from highest to lowest\ntable_res_S <- table_res[order(table_res$MeanDecreaseAccuracy),] \n\n# plot the decriptor importance as barplot\npar(mar=c(4,5,4,4))\nbarplot(table_res_S$MeanDecreaseAccuracy,\n        horiz=\"TRUE\", col=\"darkgreen\", xlab=\"importance\", xlim=c(0,0.9),\n        names.arg=row.names(table_res_S), cex.names=0.5, las=1, border=F)\n\n\n\n# Predict the model onto the satellite map\nsat_pred<-predict(sati, M_sat)\n\n# Crop the vegetation map to the study extent\nsat_crop<-crop(sat_pred, vect(sat_extent))\nsat_crop<-mask(sat_crop, vect(sat_extent))\n\n# Save the vegetation map for further processing in sat_grubbing_map\nwriteRaster(sat_crop, \"raster_output/sat_crop_new.tif\", overwrite=TRUE)"
  },
  {
    "objectID": "valley_scale_telemetry_habitat.html",
    "href": "valley_scale_telemetry_habitat.html",
    "title": "\n5  Valley scale (satellite) habitat analysis\n",
    "section": "",
    "text": "Habitat use and habitat selection assessment"
  },
  {
    "objectID": "valley_scale_telemetry_habitat.html#extract-map-values-at-gps-telemetry-positions",
    "href": "valley_scale_telemetry_habitat.html#extract-map-values-at-gps-telemetry-positions",
    "title": "\n5  Valley scale (satellite) habitat analysis\n",
    "section": "\n5.1 Extract map values at GPS telemetry positions",
    "text": "5.1 Extract map values at GPS telemetry positions\n\n# load stacked map with vegetation classes, snowmelt and disturbance probabilty\nsat_map<-rast(\"raster_output/satellite_all_map.tif\")\n# Load an extent file for the study area\nsat_extent= read_sf(\"datafiles/goose_survey_1000.shp\")\n\n#Load the goose GPS data\ngoose = read.csv(\"raster_input/goose_gps_spring2019.csv\")\ngoose_sub<-dplyr::select(goose, event.id, timestamp, ground.speed, individual.local.identifier, utm.easting, utm.northing, utm.zone)\ngoose_spat = st_as_sf(goose_sub, coords = c(\"utm.easting\", \"utm.northing\"))\n\ngoose_spat<-goose_spat %>% st_set_crs(st_crs(sat_extent))\n\ngoose_adv<-st_intersection(goose_spat, sat_extent, sparse = FALSE)\ngoose_adv = filter(goose_adv, ground.speed < 1)\n\n#Change time format\ngoose_adv <- goose_adv %>%\n  transform(timestamp = ymd_hms(timestamp))\n\ngoose_adv <- goose_adv %>%\n  mutate(year = year(timestamp),\n         month = month(timestamp),\n         day = day(timestamp),\n         jday = yday(timestamp),\n         hour = hour(timestamp),\n         minute = minute(timestamp))\n\ngoose_adv = filter(goose_adv, jday <155)\n\ngoose_adv$individual.local.identifier<-as.factor(goose_adv$individual.local.identifier)\n\n\n# Check the number of geese included in study\ntable(goose_adv$individual.local.identifier)\n\n\n   2B    2C    2F    2H    2J    2K    2M    2N    2R    2S    3B    A2 \n47808 38411  6313 17490 22267 17915 47348 43278  1088 32594   332 10686 \n\n# Extract raster information at goose positions\ngoose_sat_map<-terra::extract(sat_map , vect(goose_adv))\ngoose_sat_map<-as.data.frame(cbind(goose_sat_map, goose_adv))\n\n# add 1 to make summaries easier\ngoose_sat_map$obs<-1"
  },
  {
    "objectID": "valley_scale_telemetry_habitat.html#calculate-habitat-selection-and-use",
    "href": "valley_scale_telemetry_habitat.html#calculate-habitat-selection-and-use",
    "title": "\n5  Valley scale (satellite) habitat analysis\n",
    "section": "\n5.3 Calculate habitat selection and use",
    "text": "5.3 Calculate habitat selection and use\n\n# calculate total observations per day\ngoose_unique_mean<-group_by(goose_unique, jday) %>%\n  summarize_at(vars(obs),\n               list(~sum(., na.rm = T)))\n\ngoose_unique_mean<-rename(goose_unique_mean, unique = obs)\n\n# calculate the number of observations per day snow data available\ngoose_sat_map_goose_count_mean<-group_by(goose_sat_map, jday) %>%\n  summarize_at(vars(obs),\n               list(~sum(., na.rm = T)))\n\ngoose_sat_map_goose_count_mean<-rename(goose_sat_map_goose_count_mean, all_gps = obs)\n\n# join goose observations per day with satellite dataset\ngoose_sat_counts<-inner_join(goose_unique_mean, goose_sat_map_goose_count_mean)\ngoose_sat_counts$jday<-as.numeric(goose_sat_counts$jday)\n\n#Remove geese that are on snow\ngoose_sat_map<-filter(goose_sat_map, !(lyr1 == 0))\ngoose_sat_map<-filter(goose_sat_map, !(jday < snow_date-2)) #or -3 for other graphs\n\ngoose_sat_map<-distinct(goose_sat_map, individual.local.identifier,jday,hour, .keep_all= TRUE)\n\n# Calculate number of geese per snow free day and veg class\ngoose_sat_map_mean<-group_by(goose_sat_map, veg_class, snow, snow_date) %>%\n  summarize_at(vars(obs),\n               list(~length(.),\n                    ~sum(., na.rm = T)))\n\n# Make a frequency table for each habitat class\nrasti_sat<-freq((sat_map$snow*10) + sat_map$veg_class)    \nrasti_sat<-as.data.frame(rasti_sat)\n\n# Join the satellite habitat class frequency and number of goose observations into one table\ngoose_sat_map_mean$value<-goose_sat_map_mean$veg_class+((goose_sat_map_mean$snow)*10)\ngoose_sat_join<-inner_join(goose_sat_map_mean, rasti_sat)\n\n# Reduce table and calculate proportion of used and available habitat and the habitat use ratio\ngoose_sat_join<-dplyr::select(goose_sat_join, veg_class, snow, snow_date, gps=sum, map=count)\ngoose_sat_join$gps_p<-goose_sat_join$gps/(sum(goose_sat_join$gps))\ngoose_sat_join$map_p<-goose_sat_join$map/(sum(goose_sat_join$map))\n\n# Fix types\ngoose_sat_join$veg_class<-as.factor(goose_sat_join$veg_class)\nlevels(goose_sat_join$veg_class) <- c(\"moist\",\"dry\")\n\n# Calculate the selection ratio\ngoose_sat_join$diff<-goose_sat_join$gps_p/goose_sat_join$map_p\nlevels(goose_sat_join$veg_class) <- c(\"moss tundra\",\"dwarf shrub heath\")\n\n# Rename the datafile\nsatellite_habitat_selection<-goose_sat_join\n\n# Fix the snow day!!\nsatellite_habitat_selection$snow[satellite_habitat_selection$snow == 3]<-4\n\n# Calculate habitat selection\nsatellite_habitat_selection$maptime<-satellite_habitat_selection$map*satellite_habitat_selection$snow\nsatellite_habitat_selection$maptime_p<-satellite_habitat_selection$maptime/(sum(satellite_habitat_selection$maptime))\nsatellite_habitat_selection$maptime_diff<-satellite_habitat_selection$gps_p/satellite_habitat_selection$maptime_p\nsatellite_habitat_selection$habitat_use<-(satellite_habitat_selection$diff/sum(satellite_habitat_selection$diff))*100\nsatellite_habitat_selection$Habitat<- as.factor(c(paste0(\"Habitat\", 1:16)))\n\n# Ci values\ngoose.used<-satellite_habitat_selection$gps\ngoose.available<-satellite_habitat_selection$maptime_p\nnames(goose.available) <- names(goose.used)\nwiRatio <- widesI(goose.used, goose.available)\neb <- abs(qnorm(wiRatio$alpha/length(wiRatio$wi)))\nci_sat<-as.data.frame(eb*wiRatio$se.wi, rownames=TRUE)\nci_sat <- tibble::rownames_to_column(ci_sat, \"Habitat\")\nci_sat$Habitat<-as.factor(ci_sat$Habitat)\n\ncolnames(ci_sat) <- c(\"Habitat\", \"CI\")\n\n# join the ci values with the dataframe\nsatellite_habitat_selection<-inner_join(satellite_habitat_selection, ci_sat)"
  },
  {
    "objectID": "valley_scale_telemetry_habitat.html#compare-the-disturbance-prediction-with-habitat-selection",
    "href": "valley_scale_telemetry_habitat.html#compare-the-disturbance-prediction-with-habitat-selection",
    "title": "\n5  Valley scale (satellite) habitat analysis\n",
    "section": "\n5.4 Compare the disturbance prediction with habitat selection",
    "text": "5.4 Compare the disturbance prediction with habitat selection\n\n# Create dataframe with predicted disturbances from map\nmean_lyr_sat<-group_by(goose_sat_map, veg_class, snow) %>%\n  summarize_at(vars(lyr1),\n               list(~length(.),\n                    ~mean(., na.rm = T)))\n\n# Change formats\nmean_lyr_sat$veg_class<-as.factor(mean_lyr_sat$veg_class)\nlevels(mean_lyr_sat$veg_class) <- c(\"moss tundra\",\"dwarf shrub heath\")\n\n# Fix the snow free date\nmean_lyr_sat$snow[mean_lyr_sat$snow == 3]<-4\n\n# Join the habitat use and predicted disturbance\nall_sat<-inner_join(satellite_habitat_selection, mean_lyr_sat)\nlevels(all_sat$veg_class) <- c(\"moss tundra\",\"dwarf shrub heath\")"
  },
  {
    "objectID": "valley_scale_disturbance_map.html",
    "href": "valley_scale_disturbance_map.html",
    "title": "\n4  Valley scale (satellite) disturbance map\n",
    "section": "",
    "text": "Disturbance prediction for valley scale (satellite image) and habitat use/selection calculation"
  },
  {
    "objectID": "valley_scale_disturbance_map.html#data-preparation",
    "href": "valley_scale_disturbance_map.html#data-preparation",
    "title": "\n4  Valley scale (satellite) disturbance map\n",
    "section": "\n4.1 Data preparation",
    "text": "4.1 Data preparation\n\n# Load the cropped vegetation raster\nsat_crop<-rast(\"raster_output/sat_crop_new.tif\")\n\n# reclassify bare ground to NA\nsat_crop_cla <- classify(sat_crop, cbind(3, NA))\n\n## Load the dataset with snow-free days\n\nsn8<-rast(\"raster_output/raster_snow_all8_layers_cleaned_clipped.tif\")\n\n#Add all the elements of the stack to get unique values for snowmelt date\nsn8plus<-sn8$snow130+sn8$snow138+sn8$snow142+sn8$snow143+sn8$snow147+sn8$snow148+sn8$snow150+sn8$snow152\n\n#reclassify to get snow date\nm <- c(8, 134,\n       12, 138,\n       16, 142,\n       20, 143,\n       24, 147,\n       28, 148,\n       32, 150,\n       36, 152,\n       40,NA)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn_date <- classify(sn8plus, rclmat, include.lowest=TRUE)\n\n#reclassify to get the snow days\nm <- c(8, 22,\n       12, 18,\n       16, 14,\n       20, 13,\n       24, 9,\n       28, 8,\n       32, 6,\n       36, 3,\n       40,NA)\nrclmat <- matrix(m, ncol=2, byrow=TRUE)\nsn_snow_free <- classify(sn8plus, rclmat, include.lowest=TRUE)\n\n#Load extent (if not loaded before)\nsat_extent= read_sf(\"datafiles/goose_survey_1000.shp\")\n\n#Crop snow satellite maps to extent\nsn_snow_free_crop<-crop(sn_snow_free, vect(sat_extent))\nsn_snow_free_crop<-mask(sn_snow_free_crop, vect(sat_extent))\n\nsn_date_crop<-crop(sn_date, vect(sat_extent))\nsn_date_crop<-mask(sn_date_crop, vect(sat_extent))\nnames(sn_date_crop) <- c('snow_date')\n\n\n# make table and save for class frequencies and snowmelt for overview figure\nsat_crop_table<-as.data.frame(freq((sn_snow_free_crop*10)+sat_crop))\nwrite.table(sat_crop_table, file = \"data_output/satellite_snow_veg_class.txt\", append = FALSE, sep =  \"\\t\", dec = \".\",\n            row.names = FALSE, col.names = TRUE)"
  },
  {
    "objectID": "valley_scale_disturbance_map.html#predictive-disturbance-maps",
    "href": "valley_scale_disturbance_map.html#predictive-disturbance-maps",
    "title": "\n4  Valley scale (satellite) disturbance map\n",
    "section": "\n4.2 Predictive disturbance maps",
    "text": "4.2 Predictive disturbance maps\nUsing the predictive model to create a disturbance map for the study area\n\n# Prepare layers for disturbance prediction model\n\n# Give satellite layer dummy numbers for NA values\nsat_crop_cla_re <- classify(sat_crop_cla, cbind(NA, 1))\nsn_snow_free_crop_re <- classify(sn_snow_free_crop, cbind(NA, 22))\n\n# Take exponent of snow free days layer\nsn_snow_free_crop_re_exp <- exp(sn_snow_free_crop_re)\n\n# Raster stack for snow and veg class raster\nmap_sat<-c(sat_crop_cla_re, sn_snow_free_crop_re_exp)\nnames(map_sat) <- c('veg_class', 'expsnow')\n\n# Read the cleaned disturbance dataframe\ndf<- read.csv(\"data_output/disturbance_dataset_clean.csv\")\n\n# Take the data from the grubbing field script and run the disturbance model\nd <- dplyr::select(df, veg_class, snow, disturbance)\nd$veg_class<-as.factor(d$veg_class)\nd$expsnow <- exp(d$snow)\nlevels(d$veg_class) <- c(\"dwarf shrub heath\", \"moss tundra\")\ndf_maps<-d\nlevels(df_maps$veg_class) <- c(2,1)\nmap.drm32 <- drm(disturbance ~ expsnow, veg_class, data = df_maps,\n                 fct = LL2.3(), type = \"binomial\", pmodels = data.frame(1, veg_class, veg_class))\n\n\n#Predict map based on model\npred_map_sat<-predict(map_sat, map.drm32)\n\n\n#removing areas with bare ground (vegetated areas as 1 and bare ground as 0 and then multiply with predicted map)\nsat_crop_cla_fix <- classify(sat_crop_cla, cbind(3,0))\nsat_crop_cla_fix <- classify(sat_crop_cla_fix, cbind(2,1))\n\npred_map_sat<-pred_map_sat*sat_crop_cla_fix\n\n#removing areas covered in snow until the end of the study period\n#snow days\nsn_snow_free_crop_fix <- classify(sn8$snow152, cbind(5,0))\n\npred_map_sat<-pred_map_sat*sn_snow_free_crop_fix\npred_map_sat<- classify(pred_map_sat, cbind(0,NA))\n\n#create raster stack with snow free days, snow date, grubbing likelihood and vegetation class\nsat_map<-c(sat_crop_cla, sn_snow_free_crop, sn_date_crop, pred_map_sat)\nnames(sat_map)<-c('veg_class', 'snow', 'snow_date', 'lyr1')\n\n# save raster to avoid running the above steps again\nwriteRaster(sat_map, \"raster_output/satellite_all_map.tif\", overwrite=TRUE)\n\n# save the two vegetation classes separately for visualization\nsat_moist<-sat_map$veg_class\nsat_moist <- classify(sat_moist, cbind(2, NA))\npred_moist<-sat_map$lyr1*sat_moist\nwriteRaster(pred_moist, \"raster_output/disturbance_valley_moss.tif\", overwrite=TRUE)\n\n\nsat_dry<-sat_map$veg_class\nsat_dry <- classify(sat_dry, cbind(1, NA))\nsat_dry <- classify(sat_dry, cbind(2, 1))\npred_dry<-sat_map$lyr1*sat_dry\nwriteRaster(pred_dry, \"raster_output/disturbance_valley_dry.tif\", overwrite=TRUE)"
  },
  {
    "objectID": "valley_scale_observation.html#load-and-clean-field-data",
    "href": "valley_scale_observation.html#load-and-clean-field-data",
    "title": "\n6  Valley scale goose field observations\n",
    "section": "\n6.1 Load and clean field data",
    "text": "6.1 Load and clean field data\n\n# Load the monitoring files\ngoose_counts2019<- read.csv(\"E:/isabell_phd_springy_paper/springy_goose_counts/isabell_phd_spring2019_goose_monitoring_19_08_27.csv\", sep=\";\")\ngoose_counts2019_tod <- read.csv(\"E:/isabell_phd_springy_paper/springy_goose_counts/isabell_phd_spring2019_goose_monitoring_todalen_addition.csv\", sep=\";\")\n\n# Load the observation waypoints\ngoose_counts2019_waypoints <- read.csv(\"E:/isabell_phd_springy_paper/springy_goose_counts/isabell_phd_goose_counts2019_waypoints.csv\", sep=\";\")\n\n# merge coordinates with count dataframe\ntemp_file<-merge(x = goose_counts2019, y = goose_counts2019_waypoints, by = \"point_id\", all = TRUE)\n\n# Calculate location of goose observation\ntemp_file$y_goose<-cos(temp_file$angle*pi/180)*temp_file$distance+temp_file$y_proj\ntemp_file$x_goose<-sin(temp_file$angle*pi/180)*temp_file$distance+temp_file$x_proj\n\n#Remove rows that don't have coordinates\ntemp_file<-temp_file[complete.cases(temp_file[ , 31:32]),]"
  },
  {
    "objectID": "valley_scale_observation.html#summarize-counts-per-day",
    "href": "valley_scale_observation.html#summarize-counts-per-day",
    "title": "\n6  Valley scale goose field observations\n",
    "section": "\n6.2 Summarize counts per day",
    "text": "6.2 Summarize counts per day\n\ndf<-temp_file\n\n# Change format\ndf$count<-as.numeric(df$count)\n\n# Remove observations further than 600m\ndf<-filter(df, distance < 600)\n\n# Count goose per day\ngoose_day<-group_by(df, julian_date) %>%\n  summarize_at(vars(count),\n               list(~sum(., na.rm = T)))\n\n# Save the table with counts per day\nwrite_csv(goose_day, file = \"data_output/goose_count_observation.csv\")"
  },
  {
    "objectID": "valley_scale_observation.html#extract-habitat-information-at-observation-locations",
    "href": "valley_scale_observation.html#extract-habitat-information-at-observation-locations",
    "title": "\n6  Valley scale goose field observations\n",
    "section": "\n6.3 Extract habitat information at observation locations",
    "text": "6.3 Extract habitat information at observation locations\n\n# Clean the dataframe, select stationary geese not on snow and within 600 meters of the observer\ndf<-dplyr::select(temp_file, point_id, observation_id, julian_date, count, distance, standing, sitting, walking, eating, grazing, grubbing, vegetation, snow, gravel, water, mud, substrate_unknown, x_goose, y_goose) %>% \n  mutate(stationary = ifelse((standing < 1) & (sitting < 1)  & (eating < 1) & (grazing < 1) & (grubbing < 1), 0, 1)) %>%\n  drop_na(stationary) %>%\n  mutate(no_snow = ifelse((vegetation < 1) & (gravel < 1)  & (water < 1) & (mud < 1), 0, 1)) %>%\n  drop_na(no_snow)%>%\n  filter(distance < 600)%>%\n  dplyr::select(-standing, -sitting, -eating, -grazing, -grubbing, -walking, -stationary, -vegetation, -snow, -gravel, -water, -mud, -substrate_unknown, -no_snow)\n\n# load the satellite map from \"sat_grubbing_map\"\nall_map<-rast(\"raster_output/satellite_all_map.tif\") \n\n# Load extent file for the area of the observation study\nobs_extent= read_sf(\"datafiles/goose_survey_600.shp\")\n\n#Crop satellite map to extent\nall_map<-crop(all_map, vect(obs_extent))\nall_map<-terra::mask(all_map, vect(obs_extent))\n\n# turn the observation dataframe into a spatial layer\ndf_spat = st_as_sf(df, coords = c(\"x_goose\", \"y_goose\"))\n\n# Link the observations with the satellite map information\nall_map_df<-terra::extract(all_map , vect(df_spat))\njoin<-cbind(df,all_map_df)\n\n# keep observations that cannot be linked to a day close to when a satellite image was available\njoin_ok<-filter(join, (julian_date > snow_date-3) & (veg_class > 0))\n\n# Filter out entries that were not inluded in the join_ok dataset to find nearby matching pixels\njoin_false<-join[!join$observation_id %in% join_ok$observation_id,]\n\n# Turn into spatial layer\njoin_false_spat = st_as_sf(join_false, coords = c(\"x_goose\", \"y_goose\"))\n\n# Make a 10 meter buffer around the points that were not be able to match to a snow-free point\njoin_false_spat_buf10 = st_buffer(join_false_spat, 10)\n\n# Extract all values for buffer area\njoin_false_spat_buf_ext10x<-terra::extract(all_map , vect(join_false_spat_buf10), exact=TRUE)\n\n# Join to obtain the values of original layers\nleft<-left_join(join_false_spat_buf10, join_false_spat_buf_ext10x, by = \"ID\")\n\n# Filter to fit the criteria that the snow date is early enough and that the vegetation classes are the same\njoin_ok10<-filter(left, (julian_date > snow_date.y-3) & (!is.na(lyr1.y)))\n\n# Make new column for the date difference between the original meltout date and the one of the buffer\njoin_ok10$date_difference<-abs(join_ok10$snow_date.x-join_ok10$snow_date.y)\n\n# Remove duplicates for observation id and keep the minimum date difference\njoin_ok10_reduced<-join_ok10 %>% group_by(observation_id) %>% slice(which.min(date_difference))\n\n## Do the same again with a 20m buffer\n\n# Extract the points that haven't been matched yet\njoin_false10<-join_false[!join_false$observation_id %in% join_ok10_reduced$observation_id,]\n\n# Data that is not on a logical place\njoin_false_spat10 = st_as_sf(join_false10, coords = c(\"x_goose\", \"y_goose\"))\n\n#make a 20m buffer\njoin_false_spat_buf20 = st_buffer(join_false_spat10, 20)\n\n# Extract all values for buffer area\njoin_false_spat_buf_ext20x<-terra::extract(all_map , vect(join_false_spat_buf20), exact=TRUE)\n\n# Join to obtain the values of original layers\nleft20<-left_join(join_false_spat_buf20, join_false_spat_buf_ext20x, by = \"ID\")\n\n# Filter to fit the criteria that the snow date is early enough and that the vegetation classes are the same\njoin_ok20<-filter(left20, (julian_date > snow_date.y-3) & (!is.na(lyr1.y)))\n\n# Make new column for the date difference between the original meltout date and the one of the buffer\njoin_ok20$date_difference<-abs(join_ok20$snow_date.x-join_ok20$snow_date.y)\n\n# Remove duplicates for observation id and keep the minimum date difference\njoin_ok20_reduced<-join_ok20 %>% group_by(observation_id) %>% slice(which.min(date_difference))\n\n# Remove unnecessary columns\njoin_ok10_reduced<-as.data.frame(join_ok10_reduced)\njoin_ok10_reduced <- join_ok10_reduced[-c(7:10, 15:17)]\n\njoin_ok20_reduced<-as.data.frame(join_ok20_reduced)\njoin_ok20_reduced <- join_ok20_reduced[-c(7:10, 15:17)]\n\njoin_ok_0<-dplyr::select(join_ok, -x_goose, -y_goose)\n\n# Add column with size of buffer size\njoin_ok_0$buffer<-as.factor(\"0m\")\njoin_ok10_reduced$buffer<-as.factor(\"10m\")\njoin_ok20_reduced$buffer<-as.factor(\"20m\")\n\n# Join the dataframes together\nbind<-rbind(join_ok10_reduced, join_ok20_reduced)\nbind<-rename(bind, veg_class = veg_class.y, snow = snow.y, snow_date = snow_date.y, lyr1 = lyr1.y)\ngoose_obs_ok<-rbind(join_ok_0, bind)\ngoose_obs_ok$count<-as.numeric(goose_obs_ok$count)"
  },
  {
    "objectID": "valley_scale_observation.html#calculate-habitat-selection-and-use",
    "href": "valley_scale_observation.html#calculate-habitat-selection-and-use",
    "title": "\n6  Valley scale goose field observations\n",
    "section": "\n6.4 Calculate habitat selection and use",
    "text": "6.4 Calculate habitat selection and use\n\n# Summarize the results based on vegetation class and snow-melt date\ngoose_obs_ok_mean<-group_by(goose_obs_ok, veg_class, snow, snow_date) %>%\n  summarize_at(vars(count),\n               list(~length(.),\n                    ~sum(., na.rm = T)))\n\n\n# Make a frequency table for each habitat class\nrasti_sat<-freq((all_map$snow*10)+all_map$veg_class)\nrasti_sat<-as.data.frame(rasti_sat)\n\n# Join the satellite habitat class frequency and number of goose observations into one table\ngoose_obs_ok_mean$value<-goose_obs_ok_mean$veg_class+((goose_obs_ok_mean$snow)*10)\ngoose_obs_join<-inner_join(goose_obs_ok_mean, rasti_sat)\n\n# Reduce table and calculate proportion of used and available habitat and the selection ratio\ngoose_obs_join<-dplyr::select(goose_obs_join, veg_class, snow, snow_date, gps=sum, map=count)\ngoose_obs_join$gps_p<-goose_obs_join$gps/(sum(goose_obs_join$gps))\ngoose_obs_join$map_p<-goose_obs_join$map/(sum(goose_obs_join$map))\n\ngoose_obs_join$veg_class<-as.factor(goose_obs_join$veg_class)\nlevels(goose_obs_join$veg_class) <- c(\"moist\",\"dry\")\n\ngoose_obs_join$diff<-goose_obs_join$gps_p/goose_obs_join$map_p\n\nlevels(goose_obs_join$veg_class) <- c(\"moss tundra\",\"dwarf shrub heath\")\n\n# Fix the snow date\ngoose_obs_join$snow[goose_obs_join$snow == 3]<-4\n\n# Calculate habitat selection\ngoose_obs_join$maptime<-goose_obs_join$map*goose_obs_join$snow\ngoose_obs_join$maptime_p<-goose_obs_join$maptime/(sum(goose_obs_join$maptime))\ngoose_obs_join$maptime_diff<-goose_obs_join$gps_p/goose_obs_join$maptime_p\ngoose_obs_join$habitat_use<-(goose_obs_join$diff/sum(goose_obs_join$diff))*100\ngoose_obs_join$Habitat<- as.factor(c(paste0(\"Habitat\", 1:16)))\n\n# Ci values\ngoose.used<-goose_obs_join$gps\ngoose.available<-goose_obs_join$maptime_p\nnames(goose.available) <- names(goose.used)\nwiRatio <- widesI(goose.used, goose.available)\neb <- abs(qnorm(wiRatio$alpha/length(wiRatio$wi)))\nci_obs<-as.data.frame(eb*wiRatio$se.wi, rownames=TRUE)\nci_obs <- tibble::rownames_to_column(ci_obs, \"Habitat\")\nci_obs$Habitat<-as.factor(ci_obs$Habitat)\n\ncolnames(ci_obs) <- c(\"Habitat\", \"CI\")\n\n# Join the table with the CI values\ngoose_obs_join<-inner_join(goose_obs_join, ci_obs)"
  },
  {
    "objectID": "valley_scale_observation.html#compare-the-disturbance-prediction-with-habitat-selection",
    "href": "valley_scale_observation.html#compare-the-disturbance-prediction-with-habitat-selection",
    "title": "\n6  Valley scale goose field observations\n",
    "section": "\n6.5 Compare the disturbance prediction with habitat selection",
    "text": "6.5 Compare the disturbance prediction with habitat selection\n\n## Comparing the likelihood model with habitat selection\nmean_lyr_obs<-group_by(goose_obs_ok, veg_class, snow) %>%\n  summarize_at(vars(lyr1),\n               list(~length(.),\n                    ~mean(., na.rm = T)))\n\n# Fix formats\nmean_lyr_obs$veg_class<-as.factor(mean_lyr_obs$veg_class)\nlevels(mean_lyr_obs$veg_class) <- c(\"moss tundra\",\"dwarf shrub heath\")\nmean_lyr_obs$snow[mean_lyr_obs$snow == 3]<-4\n\n# Join the habitat use and disturbance dataframes\nall_obs<-inner_join(goose_obs_join, mean_lyr_obs)\n\n# Change level names\nlevels(all_obs$veg_class) <- c(\"moss tundra\",\"dwarf shrub heath\")\n\n\n# Save the tables\n\nwrite_csv(all_obs, file = \"data_output/satellite_observation_habitat_grubbing.csv\")"
  },
  {
    "objectID": "valley_scale_telemetry_habitat.html#count-goose-individuals-per-day",
    "href": "valley_scale_telemetry_habitat.html#count-goose-individuals-per-day",
    "title": "\n5  Valley scale (satellite) habitat analysis\n",
    "section": "\n5.2 Count goose individuals per day",
    "text": "5.2 Count goose individuals per day\n\n#Select one entry per identifier per day\ngoose_unique<-goose_sat_map[!duplicated(goose_sat_map[c(\"individual.local.identifier\",\"jday\")]),]\n\n# Count \ngoose_unique_mean<-group_by(goose_unique, jday) %>%\n  summarize_at(vars(obs),\n               list(~sum(., na.rm = T)))\n# Rename\ngoose_unique_mean<-rename(goose_unique_mean, unique = obs)\n\n# Write table (to be used in overview plot)\nwrite_csv(goose_unique_mean, file = \"data_output/goose_count_telemetry.csv\")"
  },
  {
    "objectID": "valley_scale_telemetry_habitat.html#save-the-final-output-table",
    "href": "valley_scale_telemetry_habitat.html#save-the-final-output-table",
    "title": "\n5  Valley scale (satellite) habitat analysis\n",
    "section": "\n5.5 Save the final output table",
    "text": "5.5 Save the final output table\n\nwrite_csv(all_sat, file = \"data_output/satellite_telemetry_habitat_grubbing.csv\")"
  }
]